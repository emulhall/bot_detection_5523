{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cluster_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6G_zLB8KxrL"
      },
      "source": [
        "1. K-Means\n",
        "2. Fuzzy C-means or EM\n",
        "4. DBScan\n",
        "5. Spectral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "PmzJDssKKOZ6",
        "outputId": "e3aad24a-6033-45b6-c57a-2957ac29cf32"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/Shareddrives/CSCI\\ 5523\\ -\\ Data\\ Mining\\ Final\\ Project\n",
        "!ls\n",
        "\n",
        "# import datasets\n",
        "df_labels=pd.read_csv('midterm-2018.tsv', sep='\\t')\n",
        "df_labels=df_labels.rename(columns={'2521260264':'user_id'})\n",
        "\n",
        "df_users=pd.read_json('midterm-2018_processed_user_objects.json')\n",
        "\n",
        "# Merge our user objects and labels.\n",
        "df=pd.merge(df_users, df_labels, on=['user_id'])\n",
        "\n",
        "# Look at the shape and information\n",
        "print(df.shape)\n",
        "print(df.info())\n",
        "\n",
        "# check bot vs human counts\n",
        "print(df['bot'].value_counts())\n",
        "\n",
        "# create unbalanced train and test dataframes\n",
        "train_u, test_u = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# equal datatypes check\n",
        "if all(train_u.dtypes == test_u.dtypes):\n",
        "  print(\"pass: data types are all same between train and test\")\n",
        "else:\n",
        "  print('\\nFAIL: DATA TYPES ARE NOT EQUAL BETWEEN TRAIN AND TEST, SOMETHING IS WRONG\\n')\n",
        "\n",
        "\n",
        "# create balanced train and test datframes\n",
        "bots=df[df['bot']=='bot']\n",
        "humans=df[df['bot']=='human']\n",
        "bots_sample=bots.sample(8092)\n",
        "bal_df=bots_sample.append(humans)\n",
        "\n",
        "train_b, test_b = train_test_split(bal_df, test_size=0.2)\n",
        "\n",
        "# equal datatypes check\n",
        "if all(train_b.dtypes == test_b.dtypes):\n",
        "  print(\"pass: data types are all same between train and test\")\n",
        "else:\n",
        "  print('\\nFAIL: DATA TYPES ARE NOT EQUAL BETWEEN TRAIN AND TEST, SOMETHING IS WRONG\\n')\n",
        "\n",
        "\n",
        "\n",
        "dataframes = [train_u, test_u, train_b, test_b]\n",
        "\n",
        "# clean dataframes\n",
        "cols_to_drop = ['probe_timestamp', 'user_id', 'screen_name', 'name', 'description', 'user_created_at', 'url', 'lang', 'protected', 'tid']\n",
        "\n",
        "for dataframe in dataframes:\n",
        "  dataframe.drop(labels=cols_to_drop, axis=1, inplace=True)                 # drop unused columns\n",
        "  dataframe['bot'] = [1 if val=='bot' else 0 for val in dataframe['bot']]   # convert bot column from string to int (1 for bot, 0 for human)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/Shareddrives/CSCI 5523 - Data Mining Final Project'\n",
            "/content/gdrive/Shareddrives/CSCI 5523 - Data Mining Final Project\n",
            " Balance_deprecated.ipynb   classification.ipynb   data\n",
            "'Bot Detection.gslides'     cluster_2.ipynb\t   data.ipynb\n",
            " botDetection.mp4\t    cluster.ipynb\t   Proposal.gdoc\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6cdc9cd59c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# import datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'midterm-2018.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'2521260264'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'midterm-2018.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O-COKX-No8F",
        "outputId": "07d4aed4-adb3-4b20-a2c6-b17cb2925593"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3ZoKiLuNpSN"
      },
      "source": [
        "train_u = pd.read_json('data/more_human_train.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaRME7DTNwyX"
      },
      "source": [
        "test_u = pd.read_json('data/more_human_test.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL0FobRwNxXc"
      },
      "source": [
        "train_b = pd.read_json('data/bal_train.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ATH5LFxN2pt"
      },
      "source": [
        "test_b = pd.read_json('data/bal_test.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZDoKNPrO7Zu"
      },
      "source": [
        "dataframes = [train_u, test_u, train_b, test_b]\n",
        "\n",
        "for dataframe in dataframes:\n",
        "  dataframe['bot'] = [1 if val=='bot' else 0 for val in dataframe['bot']]   # convert bot column from string to int (1 for bot, 0 for human)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PaECAU6NrEa"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def print_analysis(test, predictions, label):\n",
        "  print(\"-----------------------------------\")\n",
        "  print('{} Accuracy score: {}'.format(label, accuracy_score(test, predictions)))\n",
        "  print('{} Precision score: {}'.format(label, precision_score(test, predictions)))\n",
        "  print('{} Recall score: {}'.format(label, recall_score(test, predictions)))\n",
        "  print('{} F1 score: {}'.format(label, f1_score(test, predictions)))\n",
        "  print(\"-----------------------------------\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucOyHS_NNsK0"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# UNBALANCED\n",
        "x_train_u = train_u.to_numpy()[:,:-1].astype(int)   # all cols of train_u except for class label\n",
        "x_train_u_scaled = scaler.fit_transform(x_train_u)\n",
        "\n",
        "y_train_u = train_u.to_numpy()[:,-1].astype(int)    # only class label (last) column of train_u\n",
        "\n",
        "x_test_u = test_u.to_numpy()[:,:-1].astype(int)   # all cols of test_u except for class label\n",
        "x_test_u_scaled = scaler.transform(x_test_u)\n",
        "\n",
        "y_test_u = test_u.to_numpy()[:,-1].astype(int)    # only class label (last) column of test_u\n",
        "\n",
        "# BALANCED\n",
        "x_train_b = train_b.to_numpy()[:,:-1].astype(int)   # all cols of train_b except for class label\n",
        "x_train_b_scaled = scaler.fit_transform(x_train_b)\n",
        "\n",
        "y_train_b = train_b.to_numpy()[:,-1].astype(int)    # only class label (last) column of train_b\n",
        "\n",
        "x_test_b = test_b.to_numpy()[:,:-1].astype(int)   # all cols of test_b except for class label\n",
        "x_test_b_scaled = scaler.transform(x_test_b)\n",
        "\n",
        "y_test_b = test_b.to_numpy()[:,-1].astype(int)    # only class label (last) column of test_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXG9MHMP1umW"
      },
      "source": [
        "##Density Based Clustering: DBScan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxj1-A2NwuI"
      },
      "source": [
        "Unlike K-Means, DBScan does not have a predict function as it is not intended for classified learning (no centroids).  We can still learn things from its cluster sizes and entropy (homogeneity) however."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX6TNECW70Dw"
      },
      "source": [
        "###DBScan on unbalanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6DYgDz_xKYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "165e609b-8900-400b-9ecc-b52fc879187f"
      },
      "source": [
        "from sklearn import cluster\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "data = pd.DataFrame(x_train_u_scaled, columns=train_u.columns[:-1])\n",
        "db = DBSCAN(eps=0.005, min_samples=50).fit(data)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = pd.DataFrame(db.labels_,columns=['Cluster ID'])\n",
        "pd.DataFrame(labels, columns=['Cluster ID'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cluster ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7794</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7795</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7796</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7797</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7798</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7799 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Cluster ID\n",
              "0             -1\n",
              "1             -1\n",
              "2             -1\n",
              "3             -1\n",
              "4             -1\n",
              "...          ...\n",
              "7794          -1\n",
              "7795          -1\n",
              "7796          -1\n",
              "7797          -1\n",
              "7798          -1\n",
              "\n",
              "[7799 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWbKTjIENsWx"
      },
      "source": [
        "###Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UI0MaqrqjZn"
      },
      "source": [
        "Compare cluster sizes with class sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx2ce7JnqjGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b6e1c3-871d-40e5-f6e3-6c8d670cec7e"
      },
      "source": [
        "np.unique(pd.DataFrame(labels, columns=['Cluster ID']), return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1,  0]), array([6499, 1300]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wu6FH6dsaUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7b44b3-bc56-4692-814c-4e9b64cf5218"
      },
      "source": [
        "np.unique(y_train_u, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([6469, 1330]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyVzZ5Zkqolq"
      },
      "source": [
        "Find homogeneity completeness and v-measure scores (measurements of entropy). 1 is perfect clustering of labels, 0 is worst case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuI-hSELw7jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da25f9f-ac97-47bd-857d-0e340830d8e3"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Evaluate on training data\n",
        "np.unique(y_train_u, return_counts=True)\n",
        "#np.shape(y_train_u)\n",
        "#np.shape(labels)\n",
        "metrics.homogeneity_completeness_v_measure(y_train_u, np.ndarray.flatten((labels.to_numpy())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5755017987637634, 0.5833405123464755, 0.579394643996971)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P5cOiOl76Wv"
      },
      "source": [
        "###DBScan on balanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN73rhtm74kL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "b76d71d1-b115-44eb-ddce-7bc61e276cc3"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "data = pd.DataFrame(x_train_b_scaled, columns=train_b.columns[:-1])\n",
        "db = DBSCAN(eps=0.05, min_samples=50).fit(data)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = pd.DataFrame(db.labels_,columns=['Cluster ID'])\n",
        "pd.DataFrame(labels, columns=['Cluster ID'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cluster ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12942</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12943</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12944</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12945</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12946</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12947 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Cluster ID\n",
              "0              -1\n",
              "1               0\n",
              "2               0\n",
              "3               0\n",
              "4              -1\n",
              "...           ...\n",
              "12942           2\n",
              "12943           0\n",
              "12944           0\n",
              "12945           0\n",
              "12946           0\n",
              "\n",
              "[12947 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roF4-iymPJaZ"
      },
      "source": [
        "###Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V4dgJE9pNZh"
      },
      "source": [
        "Compare cluster sizes with class sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNt6M3R4pR_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d95e1d3-e345-4c6d-cb22-97eb2eb553c8"
      },
      "source": [
        "np.unique(pd.DataFrame(labels, columns=['Cluster ID']), return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1,  0,  1,  2,  3,  4,  5]),\n",
              " array([4991, 6824,  407,  275,  179,  135,  136]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_jiHY2WsOgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590f0bf0-bb7e-4b5f-cb66-87e2c592c64c"
      },
      "source": [
        "np.unique(y_train_b, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([6509, 6438]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN2B9Vh4pTAi"
      },
      "source": [
        "Find homogeneity completeness and v-measure scores (measurements of entropy). 1 is perfect clustering of labels, 0 is worst case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1KztorFPMfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae28b60-ab4d-480f-d2e5-4054a3f688c0"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Evaluate on training data\n",
        "np.unique(y_train_b, return_counts=True)\n",
        "#np.shape(y_train_u)\n",
        "#np.shape(labels)\n",
        "metrics.homogeneity_completeness_v_measure(y_train_b, np.ndarray.flatten((labels.to_numpy())))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6661943006476313, 0.43968063614706737, 0.5297393478421498)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxgeaB05SEyJ"
      },
      "source": [
        "##Spectral Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_trmrg_Z8BiN"
      },
      "source": [
        "###Spectral Clustering on unbalanced data\n",
        "####Takes a very long time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRb0gvgAM020"
      },
      "source": [
        "Remove outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgyKvB5WCgli"
      },
      "source": [
        "# train_u_new = train_u.drop(train_u.index[17007])\n",
        "# x_train_u_new = train_u_new.to_numpy()[:,:-1].astype(int)\n",
        "# x_train_u_new_scaled = scaler.fit_transform(x_train_u_new)\n",
        "# y_train_u_new = train_u_new.to_numpy()[:,-1].astype(int)\n",
        "\n",
        "# x_test_u_new_scaled = scaler.transform(x_test_u)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFIzDQbS2VZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f77e2d7-9e04-4292-f79d-ab109b62937a"
      },
      "source": [
        "data = pd.DataFrame(x_train_u_scaled, columns=train_u.columns[:-1])\n",
        "\n",
        "spectral = cluster.SpectralClustering(n_clusters=8,random_state=1,affinity='nearest_neighbors',gamma=100)\n",
        "spectral.fit(data)\n",
        "labels = pd.DataFrame(spectral.labels_,columns=['Cluster ID'])\n",
        "#result = pd.concat((data1,labels1), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aVqySWmXX6f"
      },
      "source": [
        "###Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DXUFrUkrCxf"
      },
      "source": [
        "Compare cluster sizes with class sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GVuDaZ9rDEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e352bf-52db-47d6-b3ed-6ba31a884844"
      },
      "source": [
        "np.unique(pd.DataFrame(labels, columns=['Cluster ID']), return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int32),\n",
              " array([2310, 3882,   11, 1480,   27,   20,   22,   47]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJlR7U4dsqnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2041a3-2f58-4205-c2e3-0202c5acbb89"
      },
      "source": [
        "np.unique(y_train_u, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([6469, 1330]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUqKqvScrDYb"
      },
      "source": [
        "Find homogeneity completeness and v-measure scores (measurements of entropy). 1 is perfect clustering of labels, 0 is worst case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWakAf0uXhjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7d64b5-d2c5-48c5-c2ff-dbbd486ab20e"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Evaluate on training data\n",
        "np.unique(y_train_u, return_counts=True)\n",
        "#np.shape(y_train_u)\n",
        "#np.shape(labels)\n",
        "metrics.homogeneity_completeness_v_measure(y_train_u, np.ndarray.flatten((labels.to_numpy())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4439873823588762, 0.181938761215739, 0.25810877264359916)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc_yxQ9D8A-E"
      },
      "source": [
        "###Spectral Clustering on balanced data\n",
        "####Takes a very long time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FcGXsETMw-I"
      },
      "source": [
        "Remove outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQIm9NDiImQe"
      },
      "source": [
        "# train_b_new = train_b.drop(train_b.index[3798])\n",
        "# x_train_b_new = train_b_new.to_numpy()[:,:-1].astype(int)\n",
        "# x_train_b_new_scaled = scaler.fit_transform(x_train_b_new)\n",
        "# y_train_b_new = train_b_new.to_numpy()[:,-1].astype(int)\n",
        "\n",
        "# x_test_b_new_scaled = scaler.transform(x_test_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meA8wiZ82VhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6560f7-6ff5-498f-fcc8-122cae8cb929"
      },
      "source": [
        "data = pd.DataFrame(x_train_b_scaled, columns=train_b.columns[:-1])\n",
        "\n",
        "spectral = cluster.SpectralClustering(n_clusters=8,random_state=1,affinity='nearest_neighbors',gamma=100)\n",
        "spectral.fit(data)\n",
        "labels = pd.DataFrame(spectral.labels_,columns=['Cluster ID'])\n",
        "#result = pd.concat((data1,labels1), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
            "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9cbancmXdmc"
      },
      "source": [
        "###Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M2rqa6irM5V"
      },
      "source": [
        "Compare cluster sizes with class sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K0d4XNqrNGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8cc25e4-9a49-491f-b86b-04e24e30267e"
      },
      "source": [
        "np.unique(pd.DataFrame(labels, columns=['Cluster ID']), return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int32),\n",
              " array([   47, 12282,    16,    43,   185,   104,    76,   194]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doEJSDl6svQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116dfc72-f868-4d86-f79a-697ffbb24792"
      },
      "source": [
        "np.unique(y_train_b, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([6509, 6438]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVUlB-2NrNSS"
      },
      "source": [
        "Find homogeneity completeness and v-measure scores (measurements of entropy). 1 is perfect clustering of labels, 0 is worst case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy2or8sL2Vor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4da491-4f9f-46d0-fcc5-433b7bb37b1d"
      },
      "source": [
        "from sklearn import metrics\n",
        "# Evaluate on training data\n",
        "np.unique(y_train_b, return_counts=True)\n",
        "#np.shape(y_train_u)\n",
        "#np.shape(labels)\n",
        "metrics.homogeneity_completeness_v_measure(y_train_b, np.ndarray.flatten((labels.to_numpy())))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.053801518079819755, 0.12849950095181228, 0.07584673152602785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    }
  ]
}